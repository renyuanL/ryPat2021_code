# -*- coding: utf-8 -*-
"""ryPattern001_LinearAlgebra.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yaL6_tVKPHg8sW2uuxKK1hZm_FfC6UEL
"""



"""# Linear Algebra

## This chapter will cover the following topics:

- Comparing scalars and vectors
- Linear equations
- Matrix operations
- Vector spaces and subspaces
- Linear maps
- Matrix decompositions


###  scalars and vectors

"""

# scalar, 純量，就是單純的數字
x1= 10
x2= 20

# vector, 一組數字，排成一列
xV= xVector= [x1,x2]
xV

# dimension, 向量中，元素的個數，
xDim= xDimension= len(xV)
xDim

# add, 向量的加法
xV1= [10, 20]
xV2= [30, 40]
xV3= xV1 + xV2 
# 這樣是錯的，它是 "Python List" 的【串接】，並非數學上向量的加法
xV3

# 運用 陽春 Python 的向量加法
xV3= [x1+x2 for x1,x2 in zip(xV1, xV2)]
xV3

# 借助 numpy 的 add 來方便操作數學上的加法
import numpy as np

xV1= [10, 20]
xV2= [30, 40]

xV3= np.add(xV1, xV2)
xV3

# 更漂亮的寫法如下，直接把向量表示成 numpy 的 核心物件 np.array()

xV1= [10, 20]
xV2= [30, 40]

xV1= np.array(xV1)
xV2= np.array(xV2)

xV3= xV1 + xV2
xV3

xV1

xV2

xV3

# multiply, 向量的乘法: (1) 純量 乘 向量 (2) 向量 (內、外)乘 向量

# (1) 純量 乘 向量 (2) 向量 (內、外)乘 向量
c= 10

xV1= [10, 20]
xV1= np.array(xV1)

xV3= c * xV1
xV3

# ((2) 向量 (內、外)乘 向量

xV1= [10, 20]
xV2= [30, 40]

xV1= np.array(xV1)
xV2= np.array(xV2)

np.dot(xV1, xV2)

np.outer(xV1, xV2)

np.outer?
'''
Compute the outer product of two vectors.
'''

np.cross(xV1, xV2)

np.cross?
'''
Return the cross product of two (arrays of) vectors.
The cross product of `a` and `b` in :math:`R^3` 
is a vector perpendicular
to both `a` and `b`. 
需要進一步畫圖解釋...
'''

# Linear equations
'''
x - 2y = 1
2x + y = 7

(x,y) = ?
'''

'''
aM xV = bV

aM= 
[[1, -2],
 [2, 1]]

xV= 
[[x1], 
 [x2]]

bV=
[[1], 
 [7]]
'''

# 矩陣 aMatrix

aM= [[1, -2],
   [2, 1]]
aM

aM + aM
# 這是錯的，它只是 python List 的串接，並非數學上 矩陣的相加

# 借助 numpy
aM = np.array(aM)
aM

aM + aM

aM * 10

aM * aM
# 這是錯的，它並非數學上矩陣的相乘，
# 僅是 矩陣中元素對元素的相乘 (element-wise multiplication)

np.matmul(aM, aM)
# 這才是正常的矩陣相乘，用紙筆算算看

# 矩陣乘法的特殊算符 @
aM @ aM

# 矩陣 乘 向量

aM= [[1, -2],
   [2, 1]]

bV= [[1], 
   [7]]

# 上面用手打完，它們 僅是 Python List，
# 須執行以下指令轉成 numpy array 
# 才有強大的 numpy 數學工具可用
aM= np.array(aM)
bV= np.array(bV)

aM

bV

# 在 numpy 裡面，向量也算矩陣的一種特例，
# 因此矩陣乘向量可以透過矩陣乘矩陣來運行 
np.matmul(aM, bV)

# 或者 使用 算符 @
aM @ bV

# 回憶一下 矩陣相乘(或矩陣乘向量)時，順序不能亂調，涉及矩陣或向量本身的形狀及維度。

bV @ aM

bV

bV.shape

aM

aM.shape

# (2,2)矩陣 可以乘 (2,1)矩陣
aM @ bV

# (2,1)矩陣 不能乘 (2,2)矩陣
bV @ aM



# Inverse matrices

# 先講矩陣世界中的單位矩陣 Identity Matrix, I
# 相當於數字世界中的 1
# 誰乘上這個 I (或 1)，都等於它自己

I= np.eye(1)
I

I= np.eye(2)
I

I= np.eye(3)
I

np.eye?
'''
Return a 2-D array with ones on the diagonal and zeros elsewhere.
'''

aM

I= np.eye(2)
I

aM @ I

I @ aM

# 有了 I 的概念，知道了任何矩陣乘上 I 會等於 那個矩陣自己
# 那麼，能否找出 任何矩陣乘上什麼東西，會等於 I 呢？
# 從數字來說， (10) * 1 = (10)
# (10) * 【?】 == 1
# 從矩陣來說 aM @ I = aM
# aM @ 【?】== I
# 答案是 【反矩陣】 (Inverse matrices)

invM= np.linalg.inv(aM) # 這個反矩陣算法(inv)藏得比較深，在 np.linalg 這個模組中
invM

aM @ invM

invM @ aM

# 走到這裡，我們終於有足夠的工具來解決 線性方程組的問題了
# Linear equations
'''
x - 2y = 1
2x + y = 7

(x,y) = ?
'''

'''
aM xV = bV

aM= 
[[1, -2],
 [2, 1]]

xV= 
[[x1], 
 [x2]]

bV=
[[1], 
 [7]]
'''

'''
aM @ xV = bV
==> 求解 xV = inv(aM) @ bV
驗算： aM @ xV ==?== bV 
'''

aM= [[1, -2],
   [2, 1]]

xV= [[x1], 
   [x2]]

bV= [[1], 
   [7]]

aM= np.array(aM)
xV= np.array(xV)
bV= np.array(bV)

# ==> 
invM= np.linalg.inv(aM)
xV= invM @ bV
xV

# 上面就是方程式之解答了
# 還可驗算一下：
左邊= aM @ xV
左邊

右邊= bV
右邊

左邊 == 右邊

# 蛤！蝦毀，怎麼全 False???
# 難道我的眼睛有業障？!@#$%^&*()
np.isclose(左邊, 右邊, rtol=1e-05, atol=1e-08, equal_nan=False)

# 這個要解釋一下....
np.isclose?
'''
Returns a boolean array where two arrays are element-wise equal 
within a tolerance.
'''

# Matrix transpose

aM

aM.transpose()

# np.linalg 模組中還有很多寶貝值得挖掘

np.linalg.solve?
'''
Solve a linear matrix equation, or system of linear scalar equations.
'''

np.linalg.solve(aM, bV)

# for more, goto
# https://numpy.org/doc/stable/reference/routines.linalg.html





# Matrix Decompositions

# https://people.duke.edu/~ccc14/sta-663-2016/07_LinearAlgebra2.html

# LU Decomposition
'''
LU stands for ‘Lower Upper’, 
and so an LU decomposition of a matrix A 
is a decomposition so that
A = LU
'''

import numpy as np
import scipy.linalg as la
np.set_printoptions(suppress=True)

A= [[1,3,4],
   [2,1,3],
   [4,1,2]]

L= [[1,0,0],
  [2,1,0],
  [4,11/5,1]]

U= [[1,3,4],
  [0,-5,-5],
  [0,0,-3]]

A= np.array(A)
L= np.array(L)
U= np.array(U)

A

L@U

np.isclose(A, L@U)

# try to synthesize a L matrix and a U matrix
# to become a A matrix

L= [ [1,0],
   [2,3]]
U= [[1,2],
  [0,3]]

L= np.array(L)
U= np.array(U)
A = L@U
A

import scipy.linalg as la
P, L, U= la.lu(A)

P

L

U

la.lu?

P@L@U

# https://docs.scipy.org/doc/scipy/reference/tutorial/linalg.html
'''
Linear Algebra (scipy.linalg)
When SciPy is built using the optimized ATLAS LAPACK and BLAS libraries, 
it has very fast linear algebra capabilities. 
If you dig deep enough, 
all of the raw LAPACK and BLAS libraries are available 
for your use for even more speed. 
In this section, some easier-to-use interfaces to these routines are described.
'''

# Basic routines
## Finding the inverse
## Solving a linear system
## Finding the determinant
## Computing norms
## Solving linear least-squares problems and pseudo-inverses
## Generalized inverse

# Decompositions
## Eigenvalues and eigenvectors
## Singular value decomposition
## LU decomposition
## Cholesky decomposition
## QR decomposition
## Schur decomposition
## Interpolative decomposition

# Matrix functions
## Exponential and logarithm functions
## Trigonometric functions
## Hyperbolic trigonometric functions
## Arbitrary function

# Special matrices

# Linear Algebra Examples
## https://people.duke.edu/~ccc14/sta-663-2016/08_LinearAlgebraExamples.html

# Applications of Linear Alebra: PCA
## https://people.duke.edu/~ccc14/sta-663-2016/09_PCA.html

