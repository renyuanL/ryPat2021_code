{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "e5e7740b-0c94-4a43-868f-6db9e830a7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real parameters used creating the data\n",
      "b=w0= -3.0000, a=w1= 4.0000 \n",
      "Exact Solution using the normal equation\n",
      "w0: -2.5703  w1: 3.8713\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression by Nomal Equation\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "\n",
    "def generateY(x, a= 1, b= 0):\n",
    "    ϵ= np.random.normal(\n",
    "        loc=   0.0, \n",
    "        scale= np.random.uniform(0,5), \n",
    "        size= x.shape)\n",
    "    y= a*x +b +ϵ\n",
    "    return y\n",
    "\n",
    "np.random.seed(0)\n",
    "N=    100\n",
    "low= -3.0\n",
    "high= 4.0\n",
    "a=  4  # 斜率\n",
    "b= -3  # y軸 截距\n",
    "\n",
    "x= np.random.uniform(low= low, \n",
    "                     high=high, \n",
    "                     size=N)\n",
    "y= generateY(x, a, b)\n",
    "\n",
    "pl.scatter(x, y, color='red', label='Real data')\n",
    "pl.axhline(color= 'gray')\n",
    "pl.axvline(color= 'gray')\n",
    "pl.xlabel('x')\n",
    "pl.ylabel('y')\n",
    "pl.title('$y=f(x)$')\n",
    "pl.legend()\n",
    "pl.grid()\n",
    "\n",
    "# the Normal Equation\n",
    "\n",
    "Φ= np.concatenate((np.ones(N).reshape(N, 1),\n",
    "                   x.reshape(N, 1)), \n",
    "                   axis=1)\n",
    "Y= y.reshape(N, 1)\n",
    "\n",
    "w= np.linalg.inv(Φ.T @Φ) @ (Φ.T@Y)    # the Normal Equation is here           \n",
    "\n",
    "w= np.squeeze(w) #只是把矩陣形狀重整一下，沒做也沒關係。\n",
    "\n",
    "print(\"Real parameters used creating the data\")\n",
    "print(f\"b=w0= {b:.4f}, a=w1= {a:.4f} \")\n",
    "print(\"Exact Solution using the normal equation\")\n",
    "print(f\"w0: {w[0]:.4f}  w1: {w[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "f7f3de4c-84ff-4ac9-a6f9-64a590277fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.figure()\n",
    "pl.plot(x, y, 'ro', label='Real data')\n",
    "\n",
    "y_gen= a * x + b\n",
    "pl.plot(x, y_gen, label='generated line equation')\n",
    "\n",
    "y_pred= w[1] * x + w[0]\n",
    "pl.plot(x, y_pred, label='predicted by Normal Equation')\n",
    "\n",
    "pl.axhline(color='gray')\n",
    "pl.axvline(color='gray')\n",
    "pl.legend()\n",
    "pl.grid()\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "8aa39053-3b3f-4fde-8c50-832ae7ef2580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, '$y$')"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HomeWorkCh04_02\n",
    "\n",
    "def generateY(x, w):\n",
    "    ϵ= np.random.normal(\n",
    "        loc=   0.0, \n",
    "        scale= np.random.uniform(1,10), \n",
    "        size= x.shape[1])    \n",
    "    x= np.concatenate(\n",
    "            (np.ones((1,N)),\n",
    "             x), \n",
    "            axis=0)\n",
    "    y= w.T@x +ϵ\n",
    "    return y\n",
    "\n",
    "np.random.seed(0)\n",
    "N=    100\n",
    "\n",
    "b= -3  # y軸 截距\n",
    "\n",
    "w= np.array([b, 3, -2]) #.reshape(-1,1)\n",
    "\n",
    "x= np.random.uniform(low= low, \n",
    "                     high=high, \n",
    "                     size=(2,N))\n",
    "\n",
    "y= generateY(x, w)\n",
    "\n",
    "\n",
    "%matplotlib qt\n",
    "ax= pl.axes(projection='3d')\n",
    "ax.scatter3D(x[0,:],x[1,:],y, color='red')\n",
    "ax.set_xlabel('$x_0$')\n",
    "ax.set_ylabel('$x_1$')\n",
    "ax.set_zlabel('$y$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "8ba21fbd-7d5a-409e-97e3-2fd63f5723a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real parameters used creating the data\n",
      "w0= -3.0000, w1= 3.0000, w2= -2.0000 \n",
      "Exact Solution using the normal equation\n",
      "w0: -2.8707  w1: 2.9854, w2: -2.0260\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.contour.QuadContourSet at 0x1fbd21a8d30>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the Normal Equation\n",
    "\n",
    "Φ= np.concatenate((np.ones((N,1)),\n",
    "                   x.T), \n",
    "                   axis=1)\n",
    "Φ.shape\n",
    "\n",
    "Y= y.reshape(N,1)\n",
    "Y.shape\n",
    "\n",
    "w_pred= np.linalg.inv(Φ.T @Φ) @ (Φ.T@Y)    # the Normal Equation is here      \n",
    "w_pred\n",
    "\n",
    "w_pred= np.squeeze(w_pred) #把矩陣形狀重整一下\n",
    "w_pred\n",
    "\n",
    "print(\"Real parameters used creating the data\")\n",
    "print(f\"w0= {w[0]:.4f}, w1= {w[1]:.4f}, w2= {w[2]:.4f} \")\n",
    "print(\"Exact Solution using the normal equation\")\n",
    "print(f\"w0: {w_pred[0]:.4f}  w1: {w_pred[1]:.4f}, w2: {w_pred[2]:.4f}\")\n",
    "\n",
    "pl.figure()\n",
    "\n",
    "ax= pl.axes(projection='3d')\n",
    "ax.scatter3D(x[0,:],x[1,:],y, color='red', label='Real data')\n",
    "ax.set_xlabel('$x_0$')\n",
    "ax.set_ylabel('$x_1$')\n",
    "ax.set_zlabel('$y$')\n",
    "\n",
    "xx= np.concatenate(\n",
    "        (np.ones((1,N)),\n",
    "         x), \n",
    "        axis=0)\n",
    "y_pred= w_pred.T@xx\n",
    "    \n",
    "ax.scatter3D(xx[1,:],xx[2,:],y_pred, color='green',  label='predicted data')\n",
    "ax.legend()\n",
    "\n",
    "x0mesh, x1mesh= np.mgrid[-3:4:.1, -3:4:.1]\n",
    "ymesh= w_pred[0] + w_pred[1] *x0mesh +  w_pred[2] *x1mesh\n",
    "\n",
    "ax.contour3D(x0mesh,x1mesh,ymesh, cmap='rainbow', levels=200) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "45b8437f-5835-407b-8e5b-8128de33e1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# this class only do 1-d data\n",
    "# 若要延伸至 2-d data, 還有很多地方要改....\n",
    "#\n",
    "class LinearRegression(object):\n",
    "    \n",
    "  def __init__(self, data_x, data_y,\n",
    "               w_init=None, \n",
    "               b_init=None, \n",
    "               learning_rate=   1e-3,\n",
    "               minLossDecrease= 1e-6):\n",
    "    \n",
    "    # a, b 須來自外部 global, 這樣不好！改...\n",
    "    \n",
    "    #scale = 4.0 #改後就用不到了\n",
    "    \n",
    "    \n",
    "    if w_init is not None:\n",
    "      self.w = w_init\n",
    "    else:\n",
    "      self.w = np.random.uniform(-1,1) #(low=a-scale, high=a+scale)\n",
    "    \n",
    "    if b_init is not None:\n",
    "      self.b = b_init\n",
    "    else:\n",
    "      self.b = np.random.uniform(-1,1) #(low=b-scale, high=b+scale)\n",
    "    print(\"w_init: {:.3f}\".format(self.w))\n",
    "    print(\"b_init: {:.3f}\".format(self.b))\n",
    "      \n",
    "    self.x= data_x\n",
    "    self.y= data_y\n",
    "    self.lr = learning_rate\n",
    "    \n",
    "    # for accumulation of loss and path (w, b)\n",
    "    \n",
    "    # 這 3 行 移到 train() 裡面\n",
    "    \n",
    "    #self.loss_history = []\n",
    "    #self.w_history = []\n",
    "    #self.b_history = []\n",
    "    \n",
    "    self.minLossDecrease= minLossDecrease\n",
    "  \n",
    "  def inference(self, x, w=None, b= None):\n",
    "    \"\"\"Inference function for a linear model\n",
    "      y_pred = w * x + b.\n",
    "      \n",
    "      # 這函數就是計算 prediction value，我也許會直接命名為 def predict()\n",
    "    \n",
    "    Args:\n",
    "      x: full-batch data, shape: (1-rank Tensor (vector) np.array)\n",
    "    \n",
    "    Returns:\n",
    "      y_pred: full-batch y_pred, shape: (1-rank Tensor (vector) np.array)\n",
    "    \n",
    "    \"\"\"\n",
    "    if w==None:\n",
    "        w= self.w\n",
    "    if b==None:\n",
    "        b= self.b\n",
    "    y_pred= w*x +b\n",
    "    return y_pred\n",
    "  \n",
    "  def loss_for_plot(self, w, b):\n",
    "    \"\"\"List of loss function with respect to given list of (w, b).\n",
    "      \n",
    "    Args:\n",
    "      w: shape: (1-rank Tensor (vector) np.array)\n",
    "      b: shape: (1-rank Tensor (vector) np.array)\n",
    "    \n",
    "    Returns:\n",
    "      loss_for_plot: shape: (1-rank Tensor (vector) np.array)\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    y_pred= np.matmul(\n",
    "             np.expand_dims(self.x, axis=1), \n",
    "             np.expand_dims(w, axis=0)\n",
    "            ) + b\n",
    "    \n",
    "    loss_for_plot= (y_pred - np.expand_dims(self.y, axis=1))**2\n",
    "    loss_for_plot= np.sum(loss_for_plot, axis=0)\n",
    "    \n",
    "    '''\n",
    "    y_pred=        self.inference(self.x, w, b)\n",
    "    loss_for_plot= self.loss_fn(self.y, y_pred)\n",
    "    '''\n",
    "    return loss_for_plot\n",
    "  \n",
    "  def loss_fn(self, labels, predictions):\n",
    "    \"\"\"Loss function.\n",
    "    MSE loss\n",
    "    \n",
    "    Args:\n",
    "      labels: target data y, shape: (1-rank Tensor (vector) np.array)\n",
    "      predictions: model inference y_pred, shape: (1-rank Tensor (vector) np.array)\n",
    "    \n",
    "    Returns:\n",
    "      loss: mean value of loss for full-batch data, shape: (0-rank Tensor (scalar))\n",
    "    \"\"\"\n",
    "    #loss = 0.5 * np.mean((predictions - labels)**2)\n",
    "    \n",
    "    # 嚴格來講，正確的理論形式應該如下：\n",
    "    loss= np.sum((predictions - labels)**2)\n",
    "    \n",
    "    return loss\n",
    "  \n",
    "  def loss_derivative(self):\n",
    "    \"\"\"Loss derivative.\n",
    "    \n",
    "    Returns:\n",
    "      dw: dL / dw, mean value of derivatives for full-batch data, shape: (0-rank Tensor (scalar))\n",
    "      db: dL / db, mean value of derivatives for full-batch data, shape: (0-rank Tensor (scalar))\n",
    "    \"\"\"\n",
    "    #dw= np.mean((self.y_pred - self.y) * self.x)\n",
    "    #db= np.mean(self.y_pred - self.y)\n",
    "    \n",
    "    # 嚴格來講，正確的理論形式應該如下：\n",
    "    dw= np.sum((self.y_pred - self.y) * self.x) *2\n",
    "    db= np.sum(self.y_pred - self.y) *2\n",
    "    \n",
    "    # 但如果是這樣，它的值較大，要讓 learning rate 更小一點，否則每一步太大會發散！\n",
    "    \n",
    "    return dw, db\n",
    "  \n",
    "  def weights_update(self):\n",
    "    \"\"\"Weights update using Gradient descent.\n",
    "    \n",
    "      w' = w - lr * dL/dw\n",
    "    \"\"\"\n",
    "    self.w +=  - self.lr * self.dw\n",
    "    self.b +=  - self.lr * self.db\n",
    "    \n",
    "  def history_update(self, loss, w, b):\n",
    "    \"\"\"Accumulate all interesting variables\n",
    "    \"\"\"\n",
    "    self.loss_history.append(loss)\n",
    "    self.w_history.append(w)\n",
    "    self.b_history.append(b)\n",
    "\n",
    "\n",
    "  def train(self, max_epochs=100, minLossDecrease=None):\n",
    "    \n",
    "    if minLossDecrease==None:\n",
    "        minLossDecrease= self.minLossDecrease\n",
    "        \n",
    "    # for accumulation of loss and path (w, b)\n",
    "    self.loss_history = []\n",
    "    self.w_history = []\n",
    "    self.b_history = []\n",
    "    \n",
    "    pre_loss = 0.0\n",
    "    for epoch in range(max_epochs):\n",
    "      \n",
    "      self.y_pred= self.inference(self.x) # 這行就是計算 prediction value\n",
    "    \n",
    "      self.loss=   self.loss_fn(self.y, self.y_pred)\n",
    "      self.history_update(self.loss, self.w, self.b)\n",
    "      \n",
    "      if epoch % 10 == 0:\n",
    "        print(\"epochs: {}  loss: {:.6f}  w: {:.5f}  b: {:.5f}\"\n",
    "              .format(epoch, self.loss, self.w, self.b))\n",
    "      \n",
    "      self.dw, self.db= self.loss_derivative()\n",
    "      self.weights_update()\n",
    "      \n",
    "      # 此處安插 連續2次疊代loss值差異太小就終止疊代的額外處理\n",
    "      if np.abs(pre_loss - self.loss) < minLossDecrease: #1e-6: \n",
    "        self.loss = self.loss_fn(self.y, self.y_pred)\n",
    "        self.history_update(self.loss, self.w, self.b)\n",
    "        print(\"epochs: {}  loss: {:.6f}  w: {:.5f}  b: {:.5f}\"\n",
    "              .format(epoch+1, self.loss, self.w, self.b))\n",
    "        break\n",
    "        \n",
    "      pre_loss = self.loss\n",
    "    \n",
    "    # 跳出 for epoch 迴圈之外，就算訓練完成\n",
    "    # 接下來只是一些 訓練過程的紀錄，方便我們觀察。\n",
    "    self.w_history = np.array(self.w_history)\n",
    "    self.b_history = np.array(self.b_history)\n",
    "    self.path= np.concatenate(\n",
    "        (np.expand_dims(self.w_history, 1), \n",
    "         np.expand_dims(self.b_history, 1)), \n",
    "        axis=1\n",
    "        ).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "9ac26f83-0036-45e9-840c-9538d5b00a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_init: -2.845\n",
      "b_init: 4.474\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-2.8449232288644155, 4.473705904889243)"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_init= np.random.uniform(-5,5) #1.0\n",
    "b_init= np.random.uniform(-5,5) #0.0\n",
    "model= LinearRegression( x, y, \n",
    "                          w_init=w_init, \n",
    "                          b_init=b_init, \n",
    "                          #learning_rate= 0.001 #0.3 \n",
    "                          # 微分項若改成 理論形式 (用sum 而非 mean)\n",
    "                          # 則此處 learning rate 要求設定更小，\n",
    "                          # 否則會發散)\n",
    "                        )\n",
    "model.w, model.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "c922227f-e1ad-4236-b330-8d9b0ee3fd34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 0  loss: 22079.136989  w: -2.84492  b: 4.47371\n",
      "epochs: 10  loss: 1318.676025  w: 3.78600  b: -1.68839\n",
      "epochs: 20  loss: 1243.547929  w: 3.86147  b: -2.46824\n",
      "epochs: 30  loss: 1242.542353  w: 3.87021  b: -2.55846\n",
      "epochs: 40  loss: 1242.528894  w: 3.87122  b: -2.56890\n",
      "epochs: 50  loss: 1242.528714  w: 3.87133  b: -2.57010\n",
      "epochs: 52  loss: 1242.528713  w: 3.87134  b: -2.57016\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3.8713378800254965, -2.5701593249573773, 1242.5287128372288)"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(1000)\n",
    "model.w, model.b, model.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "92fc0fd9-1ec0-4d99-b41c-159509132637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6.88324583e-01,  5.19700483e+00,  2.15033187e+00,  5.81815381e-01,\n",
       "       -2.70339686e+00,  3.31914746e+00, -2.32583734e+00,  9.98230922e+00,\n",
       "        1.19304761e+01, -3.79315123e+00,  7.27107295e+00,  1.48543597e-01,\n",
       "        1.20947402e+00,  1.08989083e+01, -1.22591409e+01, -1.18230243e+01,\n",
       "       -1.36362672e+01,  8.37929627e+00,  6.90338098e+00,  9.39260393e+00,\n",
       "        1.23357628e+01,  7.47251679e+00, -1.67837521e+00,  6.96767220e+00,\n",
       "       -1.09790111e+01,  3.15728047e+00, -1.02993899e+01,  1.14157550e+01,\n",
       "       -4.24147357e-02, -2.94709764e+00, -7.01488383e+00,  6.79706850e+00,\n",
       "       -1.82278854e+00,  1.22002618e+00, -1.36749813e+01,  2.55335691e+00,\n",
       "        2.40323254e+00,  2.53434670e+00,  1.13908008e+01,  4.29272429e+00,\n",
       "       -4.44173709e+00, -2.34088446e+00,  4.72118956e+00, -1.25521009e+01,\n",
       "        3.88478173e+00,  3.98968755e+00, -8.48293912e+00, -1.06903521e+01,\n",
       "       -5.63626490e+00, -4.32784197e+00,  1.26779753e+00, -2.29835039e+00,\n",
       "        1.26001306e+01, -1.14188234e+01, -8.52374548e+00, -9.81278744e+00,\n",
       "        3.51464804e+00, -7.32013134e+00, -1.54744705e+00, -7.56039459e+00,\n",
       "       -9.87619817e+00, -1.11930767e+01,  3.60194225e+00, -1.04395027e+01,\n",
       "       -8.85691576e+00, -4.19195492e+00,  8.06422236e+00, -1.15527900e+01,\n",
       "        8.52360207e+00, -1.15799671e+01,  1.22772586e+01, -1.48402292e+00,\n",
       "        1.22854324e+01,  2.20675664e+00,  5.84940072e+00, -1.31222087e+01,\n",
       "       -6.52028382e+00, -1.09269225e+01, -6.15896161e+00, -1.09667272e+01,\n",
       "       -5.56703067e+00, -2.95790880e+00, -1.24458165e+01,  4.58138186e+00,\n",
       "        1.17036674e+00, -6.99228624e+00, -4.48289479e-03, -1.16384448e+01,\n",
       "        1.42361143e+00,  1.09991640e+01, -5.55115659e+00,  3.90222463e+00,\n",
       "       -1.06125346e+01,  5.22783951e+00, -6.34145157e+00, -9.21980335e+00,\n",
       "        1.70995523e+00, -1.36392712e+01,  8.27957558e+00, -1.40569285e+01])"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred= model.inference(x)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "8939fa47-41dc-4008-b74f-a9dccc1b2b50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1fbe7d2b340>"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.scatter(x, y, label= 'generated data')\n",
    "pl.scatter(x, y_pred, label='predicted data')\n",
    "pl.grid()\n",
    "pl.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "e128a617-aa36-4735-9778-c24584554fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the loss function\n",
    "pl.figure()\n",
    "pl.title('Loss Function L')\n",
    "pl.xlabel('Number of epochs')\n",
    "pl.ylabel('Loss')\n",
    "pl.plot(model.loss_history, label='gradient descent')\n",
    "pl.legend()\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "935fa067-d9ad-4460-a2b7-71adf2df5dcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.17282033,  3.1512193 ,  3.65331914,  3.75370529,  3.78583955,\n",
       "         3.80392124,  3.81724176,  3.82777713,  3.83623634,  3.84304924,\n",
       "         3.84853955,  3.85296457,  3.85653107,  3.85940564,  3.86172252,\n",
       "         3.86358991,  3.865095  ,  3.8663081 ,  3.86728585,  3.8680739 ,\n",
       "         3.86870907,  3.86922101,  3.86963362,  3.86996619,  3.87023424,\n",
       "         3.87045028,  3.87062441,  3.87076475,  3.87087787,  3.87096905,\n",
       "         3.87104253,  3.87110176,  3.87114949,  3.87118797,  3.87121898,\n",
       "         3.87124397,  3.87126412,  3.87128036,  3.87129344,  3.87130399,\n",
       "         3.87131249,  3.87131935,  3.87132487,  3.87132932,  3.87133291,\n",
       "         3.8713358 ,  3.87133813],\n",
       "       [-0.87208947, -0.98274304, -1.25566268, -1.50508408, -1.71083625,\n",
       "        -1.87742745, -2.01181988, -2.12015852, -2.20748169, -2.27786394,\n",
       "        -2.33459154, -2.38031353, -2.41716509, -2.44686714, -2.47080675,\n",
       "        -2.49010187, -2.50565359, -2.51818814, -2.52829089, -2.53643362,\n",
       "        -2.5429966 , -2.5482863 , -2.55254976, -2.55598607, -2.55875571,\n",
       "        -2.56098802, -2.56278724, -2.5642374 , -2.56540621, -2.56634827,\n",
       "        -2.56710755, -2.56771953, -2.56821279, -2.56861034, -2.56893077,\n",
       "        -2.56918903, -2.56939719, -2.56956496, -2.56970018, -2.56980917,\n",
       "        -2.56989702, -2.56996782, -2.57002489, -2.57007088, -2.57010795,\n",
       "        -2.57013783, -2.57016191]])"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.loss_history\n",
    "model.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "cd28ebe8-136f-4feb-85ec-43fbb424de4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting together our points to plot in a 3D plot\n",
    "number_of_points = 100\n",
    "\n",
    "margin = 2\n",
    "\n",
    "w_min = model.w_history.min() - margin #-10 #a - margin\n",
    "w_max = model.w_history.max() + margin #+10 #a + margin\n",
    "b_min = model.b_history.min() - margin #-10 #b - margin\n",
    "b_max = model.b_history.max() + margin #+10 #b + margin\n",
    "\n",
    "w_points= np.linspace(w_min, w_max, number_of_points) \n",
    "b_points= np.linspace(b_min, b_max, number_of_points)\n",
    "w_mesh, b_mesh = np.meshgrid(w_points, b_points)\n",
    "loss_mesh = np.array(\n",
    "    [model.loss_for_plot(wps, bps)\n",
    "     #(wps) #, bps)\n",
    "     for wps, bps in zip(w_mesh, b_mesh)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "24090d43-2279-4ae9-b0d1-fa07d5e16d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 100), (100, 100), (100, 100))"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_mesh.shape, b_mesh.shape, loss_mesh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "e8a76ca1-b5c2-41d5-8b51-97b1c1e50e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.loss_for_plot(w_mesh, b_mesh)\n",
    "len(model.loss_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d413eb29-b5df-43b1-917f-a659d44452f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4deae367-7e4c-4674-b8c5-8491f3fc3404",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "6447990b-7580-4ed7-9c6a-e04683f4bea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mpl_toolkits.mplot3d.art3d.Line3DCollection at 0x1fbe7b50220>"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.loss_for_plot(w_mesh, b_mesh)\n",
    "fig= pl.figure(figsize=(10, 8))\n",
    "ax= pl.axes(projection='3d', elev=40, azim=-100)\n",
    "\n",
    "#ax.plot_surface(w_mesh, b_mesh, loss_mesh, cmap='rainbow')\n",
    "ax.contour(w_mesh, b_mesh, loss_mesh, levels=100, cmap='rainbow')\n",
    "\n",
    "\n",
    "#'''\n",
    "minima= (model.w, model.b)#W_exact.reshape(2, 1) # for 3D plot and contour plot\n",
    "\n",
    "\n",
    "\n",
    "ax.plot(*minima, \n",
    "        model1.loss_for_plot(*minima), \n",
    "        'ro', \n",
    "        markersize=10)\n",
    "#'''\n",
    "path= model.path\n",
    "\n",
    "ax.quiver(path[0,:-1], \n",
    "          path[1,:-1], \n",
    "          model.loss_for_plot(*path[:,:-1]),\n",
    "          path[0,1:]-path[0,:-1], \n",
    "          path[1,1:]-path[1,:-1],\n",
    "          model.loss_for_plot(*path[:,1:])- model.loss_for_plot(*path[:,:-1]),\n",
    "          color= 'gray', \n",
    "          length= .2, \n",
    "          normalize= True,\n",
    "          #scale_units= 'xy', \n",
    "          #angles= 'xy', \n",
    "          #scale= 1, \n",
    "          #color= 'blue'\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "1cfd33bf-b08d-4a39-9cd1-65ed160df9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from matplotlib.colors import LogNorm\n",
    "\n",
    "#import matplotlib\n",
    "\n",
    "fig, ax = pl.subplots(figsize=(10, 8))\n",
    "\n",
    "ax.contour(w_mesh, \n",
    "           b_mesh, \n",
    "           loss_mesh, \n",
    "           levels= 100, #np.logspace(-1, 2, 35), \n",
    "           #norm= matplotlib.colors.LogNorm(), \n",
    "           cmap='rainbow')\n",
    "ax.plot(*minima, 'ro', markersize=10)\n",
    "\n",
    "ax.quiver(path[0,:-1], \n",
    "          path[1,:-1], \n",
    "          path[0,1:]-path[0,:-1], \n",
    "          path[1,1:]-path[1,:-1],\n",
    "          scale_units= 'xy', \n",
    "          angles= 'xy', \n",
    "          scale= 1, \n",
    "          color= 'blue')\n",
    "\n",
    "ax.set_xlabel('w')\n",
    "ax.set_ylabel('b')\n",
    "\n",
    "ax.set_xlim((w_min, w_max))\n",
    "ax.set_ylim((b_min, b_max))\n",
    "\n",
    "pl.grid()\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d59d180-a940-4d09-9c53-e3bae0d0e5a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
